[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=64
subdivisions=16
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=200
max_batches = 25200
policy=steps
steps=10000,15000,20000
scales=.1,.1,.1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# Downsample

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

######################

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

### SPP ###
			#78
[maxpool]
stride=1
size=5
			#79
[route]
layers=-2
			#80
[maxpool]
stride=1
size=9
			#81
[route]
layers=-4
			#82
[maxpool]
stride=1
size=13
			#83
[route]
layers=-1,-3,-5,-6

### End SPP ###
			#84
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
			#85
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky
			#86 A ->  (w/32, h/32, 512)
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky 

### A rescale ###
#			#87 added A->B 
[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=256
activation=leaky
#			#88 added A->B (w/16,h/16,256)
[upsample]
stride=2
#			#89 route 86
[route]
layers=-3
#			#90 added A->C
[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=128
activation=leaky
#			#91 added A->C (w/8,h/8,128)
[upsample]
stride=4
### A rescale ###

#			#92
[route]
layers = -6
#			#93
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#			#94
[upsample]
stride=2
#			#95
[route]
layers = -1, 61
#			#96
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#			#97
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky
#			#98
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#			#99
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky
#			#100 B (w/16,h/16,256)
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

### B rescale ###
#			#101 added B->A (w/32,h/32,512)
[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=512
activation=leaky
#			#102 route 100
[route]
layers=-2
#			#103 added B->C
[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=128
activation=leaky
#			#104 added B->C (w/8,h/8,128)
[upsample]
stride=2
### B rescale ###

#			#105
[route]
layers = -5
#			#106
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#			#107
[upsample]
stride=2
#			#108
[route]
layers = -1, 36


#			#109
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#			#110
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky
#			#111
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#			#112 
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky
#			#113 C (w/8,h/8,128)
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

### C rescale ###
#			#114
[maxpool]
size=2
stride=2
#			#115 added C->A (w/32,h/32,512)
[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=512
activation=leaky
#			#116 route 113
[route]
layers=-3
#			#117 added C->B (w/16,h/16,256)
[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=256
activation=leaky
### C rescale ###

### ASFF A ###
#			#118
[route]
layers=86

[convolutional]
batch_normalize=1
size=1
stride=1
filters=8
activation=leaky

[route]
layers=101

[convolutional]
batch_normalize=1
size=1
stride=1
filters=8
activation=leaky

[route]
layers=115

[convolutional]
batch_normalize=1
size=1
stride=1
filters=8
activation=leaky

[route]
layers=-1,-3,-5

[convolutional]
stride=1
size=1
filters=3
activation=normalize_channels

[route]
layers=-1
group_id=0
groups=3

[scale_channels]
from=86
scale_wh=1

[route]
layers=-3
group_id=1
groups=3

[scale_channels]
from=101
scale_wh=1

[route]
layers=-5
group_id=2
groups=3

[scale_channels]
from=115
scale_wh=1

[shortcut]
from=-3
activation=linear

[shortcut]
from=-6
activation=linear

### ASFF A ###

### A yolo ###
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]		
size=1
stride=1
pad=1
filters=18
activation=linear


[yolo]
mask = 6,7,8
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=1
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
### A yolo ###

### ASFF B ###
			
[route]
layers=88

[convolutional]
batch_normalize=1
size=1
stride=1
filters=8
activation=leaky

[route]
layers=100

[convolutional]
batch_normalize=1
size=1
stride=1
filters=8
activation=leaky

[route]
layers=117

[convolutional]
batch_normalize=1
size=1
stride=1
filters=8
activation=leaky

[route]
layers=-1,-3,-5
			
[convolutional]
stride=1
size=1
filters=3
activation=normalize_channels
			
[route]
layers=-1
group_id=0
groups=3
			
[scale_channels]
from=88
scale_wh=1

[route]
layers=-3
group_id=1
groups=3

[scale_channels]
from=100
scale_wh=1

[route]
layers=-5
group_id=2
groups=3

[scale_channels]
from=117
scale_wh=1

[shortcut]
from=-3
activation=linear

[shortcut]
from=-6
activation=linear

### ASFF B ###

### B yolo ###
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=18
activation=linear


[yolo]
mask = 3,4,5
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=1
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
### B yolo ###

### ASFF C ###
			
[route]
layers=91

[convolutional]
batch_normalize=1
size=1
stride=1
filters=8
activation=leaky

[route]
layers=104

[convolutional]
batch_normalize=1
size=1
stride=1
filters=8
activation=leaky

[route]
layers=113

[convolutional]
batch_normalize=1
size=1
stride=1
filters=8
activation=leaky

[route]
layers=-1,-3,-5
			
[convolutional]
stride=1
size=1
filters=3
activation=normalize_channels
			
[route]
layers=-1
group_id=0
groups=3
			
[scale_channels]
from=91
scale_wh=1

[route]
layers=-3
group_id=1
groups=3

[scale_channels]
from=104
scale_wh=1

[route]
layers=-5
group_id=2
groups=3

[scale_channels]
from=113
scale_wh=1

[shortcut]
from=-3
activation=linear

[shortcut]
from=-6
activation=linear

### ASFF C ###

### C yolo ###
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=18
activation=linear


[yolo]
mask = 0,1,2
anchors =  57, 64,  87,113, 146,110, 116,181, 184,157, 175,230, 270,196, 236,282, 322,319
classes=1
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
### C yolo ###

