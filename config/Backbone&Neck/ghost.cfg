[net]
# Training
batch=192
subdivisions=2
#optimized_memory=1

# Testing
#batch=1
#subdivisions=1

height=224
width=224
channels=3
min_crop=128
max_crop=448

burn_in=1000
learning_rate=0.1
policy=poly
power=4
max_batches=600000
momentum=0.9
decay=0.0005

angle=7
hue=.1
saturation=.75
exposure=.75
aspect=.75

# 0
#    Conv(kernel=[3, 3], stride=2, depth=16, factor=1, se=0),

[convolutional]
batch_normalize=1
filters=16
size=3
stride=2
pad=1
activation=relu

# 1
#    Bottleneck(kernel=[3, 3], stride=1, depth=16, factor=1, se=0),

[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=8
groups=8
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=8
groups=8
size=3
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -7
activation = linear

# 2
#    Bottleneck(kernel=[3, 3], stride=2, depth=24, factor=48/16, se=0),

[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=40
groups=8
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


[convolutional]
batch_normalize=1
filters=24
groups=24
size=3
stride=2
pad=1
activation=linear


[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=16
groups=8
size=3
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -4
activation = linear


# 3
#    Bottleneck(kernel=[3, 3], stride=1, depth=24, factor=72/24, se=0),

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
groups=16
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=16
groups=8
size=3
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -7
activation = linear


# 4
#    Bottleneck(kernel=[5, 5], stride=2, depth=40, factor=72/24, se=1),

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
groups=16
size=5
stride=1
pad=1
activation=relu

[route]
layers = -1, -2

# stride = 2
[convolutional]
batch_normalize=1
filters=80
groups=80
size=5
stride=2
pad=1
activation=linear

# shortcut
[convolutional]
batch_normalize=1
filters=40
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4
[convolutional]
filters=16
size=1
stride=1
activation=relu

# excitation
[convolutional]
filters=80
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=32
groups=8
size=5
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -9
activation = linear


# 5
#    Bottleneck(kernel=[5, 5], stride=1, depth=40, factor=120/40, se=1),

[convolutional]
batch_normalize=1
filters=40
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=80
groups=40
size=5
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4
[convolutional]
filters=32
size=1
stride=1
activation=relu

# excitation
[convolutional]
filters=120
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=32
groups=8
size=5
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -11
activation = linear

# 6
#    Bottleneck(kernel=[3, 3], stride=2, depth=80, factor=240/40, se=0),


[convolutional]
batch_normalize=1
filters=80
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=160
groups=80
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


[convolutional]
batch_normalize=1
filters=80
groups=80
size=3
stride=2
pad=1
activation=linear


[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
groups=16
size=3
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -4
activation = linear


# 7
#    Bottleneck(kernel=[3, 3], stride=1, depth=80, factor=200/80, se=0),

[convolutional]
batch_normalize=1
filters=80
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=160
groups=80
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
groups=16
size=3
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -7
activation = linear

# 8
#    Bottleneck(kernel=[3, 3], stride=1, depth=80, factor=184/80, se=0),

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=128
groups=64
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
groups=16
size=3
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -7
activation = linear


# 9
#    Bottleneck(kernel=[3, 3], stride=1, depth=80, factor=184/80, se=0),

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=128
groups=64
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
groups=16
size=3
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -7
activation = linear


# 10
#    Bottleneck(kernel=[3, 3], stride=1, depth=112, factor=480/80, se=1),

# shortcut-dw
[convolutional]
batch_normalize=1
filters=80
groups=80
size=3
stride=1
pad=1
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=linear

[route]
layers = -3

[convolutional]
batch_normalize=1
filters=80
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=400
groups=80
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4
[convolutional]
filters=120
size=1
stride=1
activation=relu

# excitation
[convolutional]
filters=480
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=96
groups=32
size=3
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -12
activation = linear


# 11
#    Bottleneck(kernel=[3, 3], stride=1, depth=112, factor=672/112, se=1),

[convolutional]
batch_normalize=1
filters=224
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=448
groups=224
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4
[convolutional]
filters=168
size=1
stride=1
activation=relu

# excitation
[convolutional]
filters=672
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=96
groups=32
size=3
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -11
activation = linear


# 12
#    Bottleneck(kernel=[5, 5], stride=2, depth=160, factor=672/112, se=1),

[convolutional]
batch_normalize=1
filters=224
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=448
groups=224
size=5
stride=1
pad=1
activation=relu

[route]
layers = -1, -2

# stride = 2
[convolutional]
batch_normalize=1
filters=672
groups=672
size=5
stride=2
pad=1
activation=linear

[convolutional]
batch_normalize=1
filters=160
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4
[convolutional]
filters=168
size=1
stride=1
activation=relu

# excitation
[convolutional]
filters=672
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=40
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=120
groups=40
size=3
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -9
activation = linear


# 13
#    Bottleneck(kernel=[5, 5], stride=1, depth=160, factor=960/160, se=0),

[convolutional]
batch_normalize=1
filters=320
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=640
groups=320
size=5
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


[convolutional]
batch_normalize=1
filters=40
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=120
groups=40
size=5
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -7
activation = linear


# 14
#    Bottleneck(kernel=[5, 5], stride=1, depth=160, factor=960/160, se=1),

[convolutional]
batch_normalize=1
filters=320
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=640
groups=320
size=5
stride=1
pad=1
activation=relu

[route]
layers = -1, -2

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4
[convolutional]
filters=240
size=1
stride=1
activation=relu

# excitation
[convolutional]
filters=960
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=40
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=120
groups=40
size=5
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -11
activation = linear


# 15 
#    Bottleneck(kernel=[5, 5], stride=1, depth=160, factor=960/160, se=0),

[convolutional]
batch_normalize=1
filters=320
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=640
groups=320
size=5
stride=1
pad=1
activation=relu

[route]
layers = -1, -2


[convolutional]
batch_normalize=1
filters=40
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=120
groups=40
size=5
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -7
activation = linear

# 16
#    Bottleneck(kernel=[5, 5], stride=1, depth=160, factor=960/160, se=1),


[convolutional]
batch_normalize=1
filters=320
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=640
groups=320
size=5
stride=1
pad=1
activation=relu

[route]
layers = -1, -2

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4
[convolutional]
filters=240
size=1
stride=1
activation=relu

# excitation
[convolutional]
filters=960
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
batch_normalize=1
filters=40
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=120
groups=40
size=5
stride=1
pad=1
activation=linear

[route]
layers = -1, -2

[shortcut]
from = -11
activation = relu

# 17
#    Conv(kernel=[1, 1], stride=1, depth=960, factor=1, se=0),

[convolutional]
batch_normalize=1
filters=960
size=1
stride=1
pad=1
activation=relu

# Global avg_pool2d
[avgpool]

[dropout]
probability=.2

# 18
#    Conv(kernel=[1, 1], stride=1, depth=1280, factor=1, se=0)

[convolutional]
batch_normalize=1
filters=1280
size=1
stride=1
pad=1
activation=relu


# Head


[convolutional]
filters=1000
size=1
stride=1
pad=1
activation=linear

[softmax]
groups=1

