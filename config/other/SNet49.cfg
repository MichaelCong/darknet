[net]
# Training
batch=128
subdivisions=8
# Testing
#batch=1
#subdivisions=1
height=224
width=224
min_crop=128
max_crop=448
channels=3
momentum=0.9
decay=0.0005

burn_in=2000
learning_rate=0.1
policy=poly
power=4
max_batches=1600000

angle=7
hue=.1
saturation=.75
exposure=.75
aspect=.75


## SNet49 ##

# conv1
[convolutional]
batch_normalize=1
filters=24
size=3
stride=2
pad=1
activation=leaky

# pool1
[maxpool]
size=3
stride=2
padding=1

# stage2
[convolutional]
filters=24
groups=24
size=3
stride=2
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=30
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -3

[convolutional]
filters=30
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=30
groups=30
size=3
stride=2
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=30
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_2-1
[channel_slice]
from=-1
axis=1
start=0
end=30

[channel_slice]
from=-2
axis=1
start=30
end=60

[convolutional]
filters=30
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=30
groups=30
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=30
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_2-2
[channel_slice]
from=-1
axis=1
start=0
end=30

[channel_slice]
from=-2
axis=1
start=30
end=60

[convolutional]
filters=30
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=30
groups=30
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=30
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_2-3
[channel_slice]
from=-1
axis=1
start=0
end=30

[channel_slice]
from=-2
axis=1
start=30
end=60

[convolutional]
filters=30
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=30
groups=30
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=30
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# stage3
[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=60
groups=60
size=3
stride=2
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -4

[convolutional]
filters=60
groups=60
size=3
stride=2
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -1,-4

[channel_shuffle]
groups=2

# shufflev2_3-1
[channel_slice]
from=-1
axis=1
start=0
end=60

[channel_slice]
from=-2
axis=1
start=60
end=120

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=60
groups=60
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_3-2
[channel_slice]
from=-1
axis=1
start=0
end=60

[channel_slice]
from=-2
axis=1
start=60
end=120

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=60
groups=60
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_3-3
[channel_slice]
from=-1
axis=1
start=0
end=60

[channel_slice]
from=-2
axis=1
start=60
end=120

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=60
groups=60
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_3-4
[channel_slice]
from=-1
axis=1
start=0
end=60

[channel_slice]
from=-2
axis=1
start=60
end=120

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=60
groups=60
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_3-5
[channel_slice]
from=-1
axis=1
start=0
end=60

[channel_slice]
from=-2
axis=1
start=60
end=120

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=60
groups=60
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_3-6
[channel_slice]
from=-1
axis=1
start=0
end=60

[channel_slice]
from=-2
axis=1
start=60
end=120

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=60
groups=60
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_3-7
[channel_slice]
from=-1
axis=1
start=0
end=60

[channel_slice]
from=-2
axis=1
start=60
end=120

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=60
groups=60
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=60
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# stage4
[convolutional]
filters=120
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=120
groups=120
size=3
stride=2
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=120
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -4

[convolutional]
filters=120
groups=120
size=3
stride=2
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=120
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -1,-4

[channel_shuffle]
groups=2

# shufflev2_4-1
[channel_slice]
from=-1
axis=1
start=0
end=120

[channel_slice]
from=-2
axis=1
start=120
end=240

[convolutional]
filters=120
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=120
groups=120
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=120
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_4-2
[channel_slice]
from=-1
axis=1
start=0
end=120

[channel_slice]
from=-2
axis=1
start=120
end=240

[convolutional]
filters=120
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=120
groups=120
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=120
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# shufflev2_4-3
[channel_slice]
from=-1
axis=1
start=0
end=120

[channel_slice]
from=-2
axis=1
start=120
end=240

[convolutional]
filters=120
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[convolutional]
filters=120
groups=120
size=3
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=120
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

[route]
layers= -5,-1

[channel_shuffle]
groups=2

# conv5
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

##########################

[avgpool]

[convolutional]
filters=1000
size=1
stride=1
pad=1
activation=linear

[softmax]
groups=1

